{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashkovnikita/Telegram_bot/blob/main/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SUPF3VA1osuD"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import nltk\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/drive/MyDrive/BOT_CONFIG.json\", 'r')\n",
        "BOT_CONFIG = json.load(f)"
      ],
      "metadata": {
        "id": "2SG9c9_MFU5V"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "35Pio977os43"
      },
      "outputs": [],
      "source": [
        "texts = []\n",
        "intent_names = []\n",
        "\n",
        "for intent, intent_data in BOT_CONFIG['intents'].items():\n",
        "    for example in intent_data['examples']:\n",
        "      texts.append(example)\n",
        "      intent_names.append(intent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hql1OWDZos9M"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(2,4), analyzer = 'char')\n",
        "X = vectorizer.fit_transform(texts)\n",
        "clf=LinearSVC()\n",
        "clf.fit(X, intent_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "scores=[]\n",
        "vectorizer = CountVectorizer(ngram_range=(2, 4), analyzer='char')\n",
        "X = vectorizer.fit_transform(texts)\n",
        "\n",
        "for i in range (n):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, intent_names)\n",
        "  clf=LinearSVC()\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  score = clf.score(X_test, y_test)\n",
        "  print(score)\n",
        "  scores.append(score)\n",
        "print(scores)\n",
        "print('average=',sum(scores) / len(scores))"
      ],
      "metadata": {
        "id": "RBQcFzUXT1SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка чистоты датасета значение должно приблизиться к 100% Модель работает и тренируется сама на себе\n",
        "clf=LinearSVC()\n",
        "clf.fit(X, intent_names)\n",
        "clf.score(X, intent_names)"
      ],
      "metadata": {
        "id": "rGP8o6pjUeio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIpTXLzlvOIc"
      },
      "outputs": [],
      "source": [
        "def clear_text(text):\n",
        "  text=text.lower()\n",
        "  text=''.join(char for char in text if char in 'абвгдеёжзийклмнопрстуфхцчшщьыъэюя -abcdefghijklmnopqrstuvwxyz')\n",
        "  return(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tr0npvPpotAM"
      },
      "outputs": [],
      "source": [
        "def classify_intent(replica):\n",
        "  replica=clear_text(replica)\n",
        "\n",
        "  for intent, intent_data in BOT_CONFIG['intents'].items():\n",
        "    for example in intent_data['examples']:\n",
        "      example = clear_text(example)\n",
        "      distance = nltk.edit_distance (replica, example)\n",
        "      ##print(example,distance, round(distance / len(example),2))\n",
        "\n",
        "      if len(example) and distance / len(example) < 0.3:\n",
        "        return(intent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-x6wUJutlY_"
      },
      "outputs": [],
      "source": [
        "def classify_intent(replica):\n",
        "  intent = clf.predict(vectorizer.transform([replica]))[0]\n",
        "  examples = BOT_CONFIG['intents'][intent]['examples']\n",
        "\n",
        "  for example in examples:\n",
        "    example = clear_text(example)\n",
        "    if len(example)>0:\n",
        "\n",
        "      if abs(len(example) - len(replica)) / len(example) < 0.5:\n",
        "        distance = nltk.edit_distance (replica, example)\n",
        "        if len(example) and distance / len(example) < 0.5:\n",
        "            return(intent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfqCKxrGotDq"
      },
      "outputs": [],
      "source": [
        "def get_answer_by_intent(intent):\n",
        "  if intent in BOT_CONFIG['intents']:\n",
        "    responses = BOT_CONFIG['intents'][intent]['responses']\n",
        "    return random.choice(responses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxICIbSmO9FB"
      },
      "source": [
        "### **Generative model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1W0KTSouPosc"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/dialogues.txt') as dialogues_file:\n",
        "  dialogues_text=dialogues_file.read()\n",
        "  dialogues = dialogues_text.split('\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfKbxAxiWubH"
      },
      "outputs": [],
      "source": [
        "def clear_text(text):\n",
        "  text=text.lower()\n",
        "  text=''.join(char for char in text if char in 'абвгдеёжзийклмнопрстуфхцчшщьыъэюя -abcdefghijklmnopqrstuvwxyz')\n",
        "  return(text)\n",
        "\n",
        "dataset = []\n",
        "questions = set()\n",
        "\n",
        "for dialogue in dialogues:\n",
        "  replicas = dialogue.split('\\n')\n",
        "  replicas = replicas[:2]\n",
        "\n",
        "  if len(replicas) ==2:\n",
        "    question, answer = replicas\n",
        "    question = clear_text(question [2:])\n",
        "    answer = answer[2:]\n",
        "\n",
        "    if len(question)>0 and question not in questions:\n",
        "      questions.add(question)\n",
        "      dataset.append([question,answer])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09-GBw4KF6J4"
      },
      "outputs": [],
      "source": [
        "dataset_by_word = {} # {word: [question with word, answer], ...], ...}\n",
        "for question, answer in dataset:\n",
        "  words=question.split(' ')\n",
        "  for word in words:\n",
        "    if word not in dataset_by_word:\n",
        "      dataset_by_word[word]=[]\n",
        "    dataset_by_word[word].append([question,answer])\n",
        "\n",
        "dataset_by_word_filtered = {}\n",
        "for word, word_dataset in dataset_by_word.items():\n",
        "  if len(word_dataset) < 5000:\n",
        "    dataset_by_word_filtered[word] = word_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_by_word_count=[]\n",
        "for word, word_dataset in dataset_by_word.items():\n",
        "  dataset_by_word_count.append([word, len(word_dataset)])\n",
        "dataset_by_word_count.sort(key=lambda pair: pair[1], reverse=True)"
      ],
      "metadata": {
        "id": "0WYT4b1SQad-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjwYRR-qmEfF"
      },
      "outputs": [],
      "source": [
        "def generate_answer(replica):\n",
        "  replica=clear_text(replica)\n",
        "  if not replica:\n",
        "    return\n",
        "\n",
        "  words = set(replica.split(' '))\n",
        "  words_dataset= []\n",
        "\n",
        "  for word in words:\n",
        "    if word in dataset_by_word_filtered:\n",
        "      word_dataset = dataset_by_word_filtered[word]\n",
        "      words_dataset += word_dataset\n",
        "\n",
        "  for question, answer in words_dataset:\n",
        "    if abs(len(question) - len(replica)) / len(question) < 0.2:\n",
        "      distance = nltk.edit_distance (replica, question)\n",
        "      if distance / len(question) < 0.2:\n",
        "        return answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06465T-0nJ5l"
      },
      "source": [
        "### **Заглушка**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vgG-rBznfFO"
      },
      "outputs": [],
      "source": [
        "def get_stub():\n",
        "  failure_phrases = BOT_CONFIG['failure_phrases']\n",
        "  #TODO\n",
        "  return random.choice(failure_phrases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO8g_qhEzHI6"
      },
      "outputs": [],
      "source": [
        "stats = {'intents': 0, 'generative': 0, 'stubs': 0}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbB39XoYnmVG"
      },
      "source": [
        "### **ТЕЛО БОТА**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70SUNj50nkor"
      },
      "outputs": [],
      "source": [
        "def bot(replica):\n",
        "  # NLU\n",
        "  intent = classify_intent(replica)\n",
        "\n",
        "  # Получение ответа\n",
        "\n",
        "  # Правила\n",
        "  if intent:\n",
        "    answer = get_answer_by_intent(intent)\n",
        "    if answer:\n",
        "      stats['intents']+=1\n",
        "      return(answer)\n",
        "\n",
        "  #Генеративная модель\n",
        "  answer = generate_answer(replica)\n",
        "  if answer:\n",
        "    stats['generative']+=1\n",
        "    return(answer)\n",
        "\n",
        "  #Заглушка\n",
        "  answer=get_stub()\n",
        "  stats['stubs']+=1\n",
        "  return(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UQmOF9Lz_oJ"
      },
      "outputs": [],
      "source": [
        "stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_NE_Hb80r_U"
      },
      "outputs": [],
      "source": [
        "! pip install python-telegram-bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGLmYo3N5MhK"
      },
      "outputs": [],
      "source": [
        "! pip install nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw_nlXdf5OiY"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply() # Решение ошибки \"This event loop is already running\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Hh3y7345Ugv"
      },
      "outputs": [],
      "source": [
        "TOKEN=\"1033794649:AAFbCXQ3wJGa5ebPAY2ZcGhvXBYJ0Lb7mEs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXsSVt0X049U"
      },
      "outputs": [],
      "source": [
        "from telegram import Update # Обновление пришедшее к нам с серверов ТГ\n",
        "from telegram.ext import ApplicationBuilder, MessageHandler, filters\n",
        "\n",
        "# Создаем и настраиваем бот-приложение\n",
        "app = ApplicationBuilder().token(TOKEN).build()\n",
        "\n",
        "async def telegram_reply(upd: Update, ctx):\n",
        "    name = upd.message.from_user.full_name\n",
        "    user_text = upd.message.text\n",
        "    print(f\"{name}: {user_text}\")\n",
        "    reply = bot(user_text)\n",
        "    print(f\"BOT: {reply}\")\n",
        "    await upd.message.reply_text(reply)\n",
        "\n",
        "handler = MessageHandler(filters.TEXT, telegram_reply) # Создаем обработчик текстовых сообщений\n",
        "app.add_handler(handler) # Добавляем обработчик в приложение\n",
        "\n",
        "# app.run_polling # Наш код регулярно опрашивает сервер на предмет новых Апдейтов\n",
        "# app.run_webhook # Запускает веб-сервер, к которому будет подключаться сам ТГ и присылать туда апдейты\n",
        "app.run_polling()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "17YUgKBtwHjzsHF_bxwWuYjwdEg_xegPr",
      "authorship_tag": "ABX9TyNcwQGTp5k7EPdb7kkAYt42",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}